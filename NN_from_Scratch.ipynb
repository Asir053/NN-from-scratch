{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN_from_Scratch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuv_7Svv6uqw",
        "outputId": "ba49b4ee-9dc2-45d7-fcfe-76380b86377c"
      },
      "source": [
        "from random import seed\n",
        "from random import random\n",
        " \n",
        "# Initialize a network\n",
        "def initialize_network(n_inputs, n_hidden, n_outputs):\n",
        "\tnetwork = list()\n",
        "\thidden_layer = [{'weights':[random() for i in range(n_inputs + 1)]} for i in range(n_hidden)]\n",
        "\tnetwork.append(hidden_layer)\n",
        "\toutput_layer = [{'weights':[random() for i in range(n_hidden + 1)]} for i in range(n_outputs)]\n",
        "\tnetwork.append(output_layer)\n",
        "\treturn network\n",
        " \n",
        "seed(1)\n",
        "network = initialize_network(2, 4, 1)\n",
        "for layer in network:\n",
        "\tprint(layer)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'weights': [0.13436424411240122, 0.8474337369372327, 0.763774618976614]}, {'weights': [0.2550690257394217, 0.49543508709194095, 0.4494910647887381]}, {'weights': [0.651592972722763, 0.7887233511355132, 0.0938595867742349]}, {'weights': [0.02834747652200631, 0.8357651039198697, 0.43276706790505337]}]\n",
            "[{'weights': [0.762280082457942, 0.0021060533511106927, 0.4453871940548014, 0.7215400323407826, 0.22876222127045265]}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFrExvgwGVDO",
        "outputId": "a08b7ff2-c933-4850-df9d-f58727d47a19"
      },
      "source": [
        "from math import exp\n",
        " \n",
        "# Calculate neuron activation for an input\n",
        "def activate(weights, inputs):\n",
        "  activation = weights[-1]\n",
        "  for i in range(len(weights)-1):\n",
        "    activation += weights[i] * inputs[i]\n",
        "  return activation\n",
        " \n",
        "# Transfer neuron activation\n",
        "def transfer_ReLU(activation):\n",
        "  return activation if (activation>0) else 0\n",
        "\n",
        "\n",
        "def transfer_sigmoid(activation):\n",
        "  return 1.0 / (1.0 + exp(-activation))\n",
        " \n",
        "# Forward propagate input to a network output\n",
        "def forward_propagate(network, row):\n",
        "  inputs = row\n",
        "  for i,layer in enumerate(network):\n",
        "    new_inputs = []\n",
        "    for neuron in layer:\n",
        "      activation = activate(neuron['weights'], inputs)\n",
        "      neuron['output'] = transfer_sigmoid(activation) if (i== len(network)-1) else transfer_ReLU(activation)\n",
        "      new_inputs.append(neuron['output'])\n",
        "    inputs = new_inputs; print(inputs)\n",
        "    # print(inputs)\n",
        "  return inputs\n",
        " \n",
        "# test forward propagation\n",
        "network = [[{'weights': [0.13436424411240122, 0.8474337369372327, 0.763774618976614]}, {'weights': [0.2550690257394217, 0.49543508709194095, 0.4494910647887381]}, {'weights': [0.651592972722763, 0.7887233511355132, 0.0938595867742349]}, {'weights': [0.02834747652200631, 0.8357651039198697, 0.43276706790505337]}],\n",
        "[{'weights': [0.762280082457942, 0.0021060533511106927, 0.4453871940548014, 0.7215400323407826, 0.22876222127045265]}]]\n",
        "row = [1, 0, None]\n",
        "output = forward_propagate(network, row)\n",
        "# print(output)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.8981388630890152, 0.7045600905281598, 0.7454525594969978, 0.4611145444270597]\n",
            "[0.8291488603399905]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1eZYdpHnJ_IX",
        "outputId": "35af02be-a977-4c1e-accc-ca6fcfadbacf"
      },
      "source": [
        "# Calculate the derivative of an neuron output\n",
        "def derivative_sigmoid(output):\n",
        "\treturn output * (1.0 - output)\n",
        " \n",
        "def derivative_ReLU(output):\n",
        "\treturn 1 if (output>0) else 0\n",
        " \n",
        "# Backpropagate error and store in neurons\n",
        "def backward_propagate_error(network, expected):\n",
        "\tfor i in reversed(range(len(network))):\n",
        "\t\tlayer = network[i]\n",
        "\t\terrors = list()\n",
        "\t\tif i != len(network)-1:\n",
        "\t\t\tfor j in range(len(layer)):\n",
        "\t\t\t\terror = 0.0\n",
        "\t\t\t\tfor neuron in network[i + 1]:\n",
        "\t\t\t\t\terror += (neuron['weights'][j] * neuron['delta'])\n",
        "\t\t\t\terrors.append(error)\n",
        "\t\telse:\n",
        "\t\t\tfor j in range(len(layer)):\n",
        "\t\t\t\tneuron = layer[j]\n",
        "\t\t\t\terrors.append(expected[j] - neuron['output'])\n",
        "\t\tfor j in range(len(layer)):\n",
        "\t\t\tneuron = layer[j]\n",
        "\t\t\tneuron['delta'] = (errors[j] * derivative_ReLU(neuron['output'])) if (i != len(network)-1) else (errors[j] * derivative_sigmoid(neuron['output']))\n",
        " \n",
        "# test backpropagation of error\n",
        "network = [[{'output': 0.7105668883115941,'weights': [0.13436424411240122, 0.8474337369372327, 0.763774618976614]}, {'output': 0.6691980263750579,'weights': [0.2550690257394217, 0.49543508709194095, 0.4494910647887381]}, {'output': 0.678187028346445,'weights': [0.651592972722763, 0.7887233511355132, 0.0938595867742349]}, {'output': 0.6132785437303728,'weights': [0.02834747652200631, 0.8357651039198697, 0.43276706790505337]}],\n",
        "[{'output': 0.8200053021353443,'weights': [0.762280082457942, 0.0021060533511106927, 0.4453871940548014, 0.7215400323407826, 0.22876222127045265]}]]\n",
        "expected = [1]\n",
        "backward_propagate_error(network, expected)\n",
        "for layer in network:\n",
        "\tprint(layer)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'output': 0.7105668883115941, 'weights': [0.13436424411240122, 0.8474337369372327, 0.763774618976614], 'delta': 0.020251195078642776}, {'output': 0.6691980263750579, 'weights': [0.2550690257394217, 0.49543508709194095, 0.4494910647887381], 'delta': 5.5950690882343974e-05}, {'output': 0.678187028346445, 'weights': [0.651592972722763, 0.7887233511355132, 0.0938595867742349], 'delta': 0.011832426374371074}, {'output': 0.6132785437303728, 'weights': [0.02834747652200631, 0.8357651039198697, 0.43276706790505337], 'delta': 0.019168870193836673}]\n",
            "[{'output': 0.8200053021353443, 'weights': [0.762280082457942, 0.0021060533511106927, 0.4453871940548014, 0.7215400323407826, 0.22876222127045265], 'delta': 0.026566606611763487}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kx9BjEwKDIYT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}